{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tab_data = '/Users/cbun/Dropbox/Cancer-Test-Problems/FOLFOX-Study/folfox-rma-all-label.tab'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Helper Methods\n",
    "`generate_datasets`: Randomly split and filter training/test data\n",
    "\n",
    "`top_important_features`: Return a sorted list of the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_datasets(X, y, training_pct=80, feature_list=None):\n",
    "    # Generate training / test sets\n",
    "    if feature_list: # Filter\n",
    "        X = X[feature_list]\n",
    "    mask = np.random.rand(len(folfox_data)) < training_pct / 100.0\n",
    "    return {\n",
    "        'training': X[mask],\n",
    "        'training_truth': y[mask],\n",
    "        'test': X[~mask],\n",
    "        'test_truth': y[~mask]\n",
    "    }\n",
    "\n",
    "def top_important_features(X_train, num_features, rf_estimator):\n",
    "    fi = rf_estimator.feature_importances_\n",
    "    cols = X_train.columns\n",
    "    features = [{'importance':f, 'name':n} for f,n in zip(fi,cols)]\n",
    "    top = sorted(features, reverse=True)[:num_features]\n",
    "    return top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Import Data\n",
    "Data is transposed and pandas did not like the mixed-types, so move some data around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "folfox_df = pd.read_csv(tab_data, sep='\\t', skiprows=[1]).drop('identifier', 1)\n",
    "\n",
    "# Transpose and relabel\n",
    "folfox_data = folfox_df.transpose()[1:]\n",
    "folfox_data.columns = folfox_data.iloc[0]\n",
    "folfox_data = folfox_data.ix[1:, :]\n",
    "\n",
    "# Get targets and encode as integers\n",
    "from sklearn import preprocessing\n",
    "response_row = pd.read_csv(tab_data, sep='\\t', nrows=1)\n",
    "response_col = response_row.transpose()[3:].ix[:,0]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(response_col)\n",
    "folfox_data_y = le.transform(response_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "#### Heare's what the data looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 83 x 54675\n",
      "probe       1007_s_at   1053_at    117_at    121_at 1255_g_at   1294_at  \\\n",
      "gsm710801_R  11.19218  6.774634  8.343318  8.031042  3.327017  7.830977   \n",
      "gsm710802_R  10.49652  7.804514  5.595647  8.247604  3.103164   6.50772   \n",
      "gsm710803_R  10.59073  7.161205  5.526806  7.672077  3.365848  7.236786   \n",
      "gsm710804_R  9.866778  7.137549  5.941534  7.515458  3.084327  8.178657   \n",
      "gsm710805_R  9.834763  6.863142  5.754606  7.203127  3.174936  7.027632   \n",
      "\n",
      "probe         1316_at   1320_at 1405_i_at   1431_at       ...        \\\n",
      "gsm710801_R  4.880257  4.675249    6.4275  8.615556       ...         \n",
      "gsm710802_R   5.29335  4.727968  5.068135  3.759907       ...         \n",
      "gsm710803_R  5.066042  4.735936  5.995342  3.760872       ...         \n",
      "gsm710804_R  4.621971  4.551727  8.448129  6.275264       ...         \n",
      "gsm710805_R  4.704785  4.258746  5.669158  3.750633       ...         \n",
      "\n",
      "probe       AFFX-r2-Ec-bioD-3_at AFFX-r2-Ec-bioD-5_at AFFX-r2-P1-cre-3_at  \\\n",
      "gsm710801_R             11.56657             10.81077            13.44964   \n",
      "gsm710802_R             11.28158             10.70909            13.11465   \n",
      "gsm710803_R              11.0786             10.71776            12.91448   \n",
      "gsm710804_R             12.83233             12.06598             13.9038   \n",
      "gsm710805_R             13.35249             12.73568            14.20111   \n",
      "\n",
      "probe       AFFX-r2-P1-cre-5_at AFFX-ThrX-3_at AFFX-ThrX-5_at AFFX-ThrX-M_at  \\\n",
      "gsm710801_R            13.14278       3.604884       3.605932       3.159124   \n",
      "gsm710802_R            12.94053       3.536764       3.550939       2.972436   \n",
      "gsm710803_R            12.77905        3.77187       3.599765        3.11158   \n",
      "gsm710804_R            13.91762       3.510213       3.437387       3.008122   \n",
      "gsm710805_R            14.11949       3.573411       3.402293       3.059147   \n",
      "\n",
      "probe       AFFX-TrpnX-3_at AFFX-TrpnX-5_at AFFX-TrpnX-M_at  \n",
      "gsm710801_R        2.949194         3.32688        3.142712  \n",
      "gsm710802_R         3.09163        3.275043        3.220545  \n",
      "gsm710803_R        3.126122        3.254758        3.447137  \n",
      "gsm710804_R        2.983326        3.055302        3.114483  \n",
      "gsm710805_R        2.894489        3.270851        3.109425  \n",
      "\n",
      "[5 rows x 54675 columns]\n"
     ]
    }
   ],
   "source": [
    "print 'Full dataset: {} x {}'.format(*folfox_data.shape)\n",
    "print folfox_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "### Random forests with recursive feature elimination\n",
    "This function will run iteratively, each time, trimming a percentage of the unimportant features.  It will continue to run until it reaches a `min_features` limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def rf_eliminate(X, y, elim_pct=20,\n",
    "                 start_n_estimators=10000, n_estimators=2000,\n",
    "                 min_features=15, iter_num=0):\n",
    "    if iter_num == 0:\n",
    "        n_estimators = start_n_estimators\n",
    "\n",
    "    # Get training / test sets\n",
    "    data = generate_datasets(X, y)\n",
    "    X_train = data['training']\n",
    "    y_train = data['training_truth']\n",
    "    X_test = data['test']\n",
    "    y_test = data['test_truth']\n",
    "\n",
    "    # Run RF\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rf.fit(X_train, y_train)\n",
    "    score = rf.score(X_test, y_test)\n",
    "    print '{0}\\nPass #{1}\\n{0}'.format('='*20, iter_num+1)\n",
    "    print 'Training set: {}x{}'.format(*X_train.shape)\n",
    "    print 'Score: {}'.format(score)\n",
    "\n",
    "    # Get top features\n",
    "    num_features = int(len(X_train.columns) * (1 - (elim_pct / 100.0)))\n",
    "    top_info = top_important_features(X_train, num_features, rf)\n",
    "    if num_features < min_features:\n",
    "        top_probes = top_important_features(X_train, len(X_train.columns), rf)\n",
    "        print 'Minimum Features reached'\n",
    "        print 'Top Probes:'\n",
    "        for i,probe in enumerate(top_probes):\n",
    "            print '{}\\t{}\\t{}'.format(i+1, probe['name'], probe['importance'])\n",
    "        return\n",
    "    top_info = top_important_features(X_train, num_features, rf)\n",
    "    top_fnames =  [probe['name'] for probe in top_info]\n",
    "    # Trim feature set and re-run\n",
    "    \n",
    "    trimmed_X = X[top_fnames]\n",
    "    rf_eliminate(trimmed_X, y, elim_pct=elim_pct, n_estimators=n_estimators,\n",
    "                 min_features=min_features, iter_num=iter_num+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "* Initial number of estimators: 2000\n",
    "* number of estimators thereafter: 500\n",
    "* Percentage of features to eliminate each iteration: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Pass #1\n",
      "====================\n",
      "Training set: 65x54675\n",
      "Score: 0.777777777778\n",
      "====================\n",
      "Pass #2\n",
      "====================\n",
      "Training set: 70x43740\n",
      "Score: 0.692307692308\n",
      "====================\n",
      "Pass #3\n",
      "====================\n",
      "Training set: 59x34992\n",
      "Score: 0.708333333333\n",
      "====================\n",
      "Pass #4\n",
      "====================\n",
      "Training set: 65x27993\n",
      "Score: 0.666666666667\n",
      "====================\n",
      "Pass #5\n",
      "====================\n",
      "Training set: 66x22394\n",
      "Score: 0.823529411765\n",
      "====================\n",
      "Pass #6\n",
      "====================\n",
      "Training set: 67x17915\n",
      "Score: 0.5625\n",
      "====================\n",
      "Pass #7\n",
      "====================\n",
      "Training set: 63x14332\n",
      "Score: 0.75\n",
      "====================\n",
      "Pass #8\n",
      "====================\n",
      "Training set: 72x11465\n",
      "Score: 0.727272727273\n",
      "====================\n",
      "Pass #9\n",
      "====================\n",
      "Training set: 71x9172\n",
      "Score: 0.75\n",
      "====================\n",
      "Pass #10\n",
      "====================\n",
      "Training set: 72x7337\n",
      "Score: 0.636363636364\n",
      "====================\n",
      "Pass #11\n",
      "====================\n",
      "Training set: 69x5869\n",
      "Score: 0.642857142857\n",
      "====================\n",
      "Pass #12\n",
      "====================\n",
      "Training set: 72x4695\n",
      "Score: 0.909090909091\n",
      "====================\n",
      "Pass #13\n",
      "====================\n",
      "Training set: 72x3756\n",
      "Score: 0.636363636364\n",
      "====================\n",
      "Pass #14\n",
      "====================\n",
      "Training set: 62x3004\n",
      "Score: 1.0\n",
      "====================\n",
      "Pass #15\n",
      "====================\n",
      "Training set: 68x2403\n",
      "Score: 0.8\n",
      "====================\n",
      "Pass #16\n",
      "====================\n",
      "Training set: 71x1922\n",
      "Score: 0.75\n",
      "====================\n",
      "Pass #17\n",
      "====================\n",
      "Training set: 66x1537\n",
      "Score: 0.764705882353\n",
      "====================\n",
      "Pass #18\n",
      "====================\n",
      "Training set: 60x1229\n",
      "Score: 1.0\n",
      "====================\n",
      "Pass #19\n",
      "====================\n",
      "Training set: 71x983\n",
      "Score: 0.833333333333\n",
      "====================\n",
      "Pass #20\n",
      "====================\n",
      "Training set: 61x786\n",
      "Score: 0.772727272727\n",
      "====================\n",
      "Pass #21\n",
      "====================\n",
      "Training set: 67x628\n",
      "Score: 0.875\n",
      "====================\n",
      "Pass #22\n",
      "====================\n",
      "Training set: 71x502\n",
      "Score: 0.916666666667\n",
      "====================\n",
      "Pass #23\n",
      "====================\n",
      "Training set: 66x401\n",
      "Score: 0.764705882353\n",
      "====================\n",
      "Pass #24\n",
      "====================\n",
      "Training set: 69x320\n",
      "Score: 0.857142857143\n",
      "====================\n",
      "Pass #25\n",
      "====================\n",
      "Training set: 69x256\n",
      "Score: 0.928571428571\n",
      "====================\n",
      "Pass #26\n",
      "====================\n",
      "Training set: 65x204\n",
      "Score: 1.0\n",
      "====================\n",
      "Pass #27\n",
      "====================\n",
      "Training set: 69x163\n",
      "Score: 0.714285714286\n",
      "====================\n",
      "Pass #28\n",
      "====================\n",
      "Training set: 64x130\n",
      "Score: 0.789473684211\n",
      "====================\n",
      "Pass #29\n",
      "====================\n",
      "Training set: 65x104\n",
      "Score: 1.0\n",
      "====================\n",
      "Pass #30\n",
      "====================\n",
      "Training set: 65x83\n",
      "Score: 0.944444444444\n",
      "====================\n",
      "Pass #31\n",
      "====================\n",
      "Training set: 65x66\n",
      "Score: 0.944444444444\n",
      "====================\n",
      "Pass #32\n",
      "====================\n",
      "Training set: 66x52\n",
      "Score: 0.823529411765\n",
      "====================\n",
      "Pass #33\n",
      "====================\n",
      "Training set: 72x41\n",
      "Score: 1.0\n",
      "====================\n",
      "Pass #34\n",
      "====================\n",
      "Training set: 62x32\n",
      "Score: 0.904761904762\n",
      "====================\n",
      "Pass #35\n",
      "====================\n",
      "Training set: 62x25\n",
      "Score: 0.809523809524\n",
      "====================\n",
      "Pass #36\n",
      "====================\n",
      "Training set: 70x20\n",
      "Score: 0.923076923077\n",
      "====================\n",
      "Pass #37\n",
      "====================\n",
      "Training set: 71x16\n",
      "Score: 0.916666666667\n",
      "Minimum Features reached\n",
      "Top Probes:\n",
      "1\t218079_s_at\t0.10175108966\n",
      "2\t208771_s_at\t0.0993537018376\n",
      "3\t201455_s_at\t0.0925025871808\n",
      "4\t227489_at\t0.0878375900774\n",
      "5\t227323_at\t0.0824671213926\n",
      "6\t224886_at\t0.0714573827232\n",
      "7\t237054_at\t0.056445312361\n",
      "8\t226298_at\t0.0526101309395\n",
      "9\t237749_at\t0.0524714288082\n",
      "10\t226797_at\t0.052138665043\n",
      "11\t237204_at\t0.0495928426529\n",
      "12\t230141_at\t0.0483703813247\n",
      "13\t212620_at\t0.045039528049\n",
      "14\t203678_at\t0.0374598444497\n",
      "15\t225910_at\t0.0353893517887\n",
      "16\t227656_at\t0.0351130417116\n"
     ]
    }
   ],
   "source": [
    "rf_eliminate(folfox_data, folfox_data_y, start_n_estimators=2000, n_estimators=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "* Initial number of estimators: 10000\n",
    "* number of estimators thereafter: 200\n",
    "* Percentage of features to eliminate each iteration: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Pass #1\n",
      "====================\n",
      "Training set: 59x54675\n",
      "Score: 0.625\n",
      "====================\n",
      "Pass #2\n",
      "====================\n",
      "Training set: 66x27337\n",
      "Score: 0.705882352941\n",
      "====================\n",
      "Pass #3\n",
      "====================\n",
      "Training set: 65x13668\n",
      "Score: 0.777777777778\n",
      "====================\n",
      "Pass #4\n",
      "====================\n",
      "Training set: 69x6834\n",
      "Score: 0.785714285714\n",
      "====================\n",
      "Pass #5\n",
      "====================\n",
      "Training set: 64x3417\n",
      "Score: 0.736842105263\n",
      "====================\n",
      "Pass #6\n",
      "====================\n",
      "Training set: 64x1708\n",
      "Score: 0.842105263158\n",
      "====================\n",
      "Pass #7\n",
      "====================\n",
      "Training set: 68x854\n",
      "Score: 0.866666666667\n",
      "====================\n",
      "Pass #8\n",
      "====================\n",
      "Training set: 61x427\n",
      "Score: 0.954545454545\n",
      "====================\n",
      "Pass #9\n",
      "====================\n",
      "Training set: 63x213\n",
      "Score: 0.9\n",
      "====================\n",
      "Pass #10\n",
      "====================\n",
      "Training set: 61x106\n",
      "Score: 0.909090909091\n",
      "====================\n",
      "Pass #11\n",
      "====================\n",
      "Training set: 69x53\n",
      "Score: 0.785714285714\n",
      "====================\n",
      "Pass #12\n",
      "====================\n",
      "Training set: 68x26\n",
      "Score: 1.0\n",
      "Minimum Features reached\n",
      "Top Probes:\n",
      "1\t201455_s_at\t0.0862959506777\n",
      "2\t218079_s_at\t0.0846730966588\n",
      "3\t208771_s_at\t0.0791105057464\n",
      "4\t244527_at\t0.0430365568772\n",
      "5\t224886_at\t0.040049900509\n",
      "6\t217913_at\t0.0395160611498\n",
      "7\t237749_at\t0.0393502551354\n",
      "8\t231850_x_at\t0.0383067342518\n",
      "9\t208975_s_at\t0.0380180602502\n",
      "10\t201454_s_at\t0.0373384750416\n",
      "11\t1563801_at\t0.0358980540044\n",
      "12\t226797_at\t0.0358756828041\n",
      "13\t237054_at\t0.0358179040068\n",
      "14\t226298_at\t0.0357657640043\n",
      "15\t225874_at\t0.0355095239585\n",
      "16\t237204_at\t0.0343958269667\n",
      "17\t227323_at\t0.0327450089635\n",
      "18\t223236_at\t0.0312867928647\n",
      "19\t231912_s_at\t0.0298379177771\n",
      "20\t224383_at\t0.0277705563027\n",
      "21\t242528_at\t0.0260822580641\n",
      "22\t224308_s_at\t0.0257385450132\n",
      "23\t223443_s_at\t0.0250692569292\n",
      "24\t242502_at\t0.0226814210683\n",
      "25\t220631_at\t0.0210518794338\n",
      "26\t229724_at\t0.0187780115407\n"
     ]
    }
   ],
   "source": [
    "rf_eliminate(folfox_data, folfox_data_y, start_n_estimators=10000, n_estimators=2000, elim_pct=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "### //TODO: Cross Validation Stuff\n",
    "Use a 10-fold stratified cross-validation and grid parameter search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.671875\n",
      "Best parameters: {'min_samples_split': 2, 'n_estimators': 2000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "cross_validation = StratifiedKFold(folfox_training_truth, n_folds=10, shuffle=True)\n",
    "parameter_grid = {'n_estimators': [200, 500, 1000, 1500, 2000],\n",
    "                  'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=parameter_grid, cv=cross_validation)\n",
    "grid_search.fit(folfox_training, folfox_training_truth)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "rf_best = grid_search.best_estimator_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
